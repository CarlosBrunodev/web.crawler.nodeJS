# web.crawler.nodeJS

O que é web crawler? Web crawler, bot ou web spider é um algoritmo usado pelos buscadores para encontrar, 
ler e indexar páginas de um site. É como um robô que captura informações de cada um dos links que encontra pela frente, cadastra e
compreende o que é mais relevante.
